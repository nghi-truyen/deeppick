#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{indentfirst}
\usepackage[useregional]{datetime2}

\author{Ngo Nghi Truyen Huynh}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement !tph
\paperfontsize 11
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title

\lang french
\begin_inset Graphics
	filename figs/insa-logo.png
	lyxscale 15
	height 1.5cm

\end_inset


\begin_inset space \hspace{}
\length 0.5cm
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset VSpace 0.5cm
\end_inset


\begin_inset Graphics
	filename /home/nnthuynh/Desktop/stage_5A/realisation/compte-rendu/figs/logo-GET.png
	lyxscale 15
	height 1.75cm

\end_inset


\begin_inset space \hspace{}
\length 0.5cm
\end_inset


\begin_inset Graphics
	filename figs/OMP_logo.png
	lyxscale 15
	height 2cm

\end_inset


\begin_inset space \hspace{}
\length 0.5cm
\end_inset


\begin_inset Graphics
	filename figs/cnrs-logo.png
	lyxscale 15
	height 2cm

\end_inset


\begin_inset space \hspace{}
\length 0.5cm
\end_inset


\begin_inset Graphics
	filename figs/Logo-ISAE-SUPAERO.png
	lyxscale 15
	height 2cm

\end_inset


\begin_inset space \hspace{}
\length 0.5cm
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset VSpace 1.2cm
\end_inset

 ——— WORK PLACEMENT REPORT ———
\lang english
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vskip 1cm
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
textbf{Automatic arrival time picking for seismic inversion}
\end_layout

\end_inset

 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vskip 1cm
\end_layout

\end_inset

 ——————————————————————— 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vskip 1cm
\end_layout

\end_inset


\end_layout

\begin_layout Date

\shape italic
September 2021
\end_layout

\begin_layout Standard
\align center

\series bold
\shape italic
Tutors:
\end_layout

\begin_layout Standard
\align center
Dr.
 Roland Martin
\end_layout

\begin_layout Standard
\align center
Prof.
 Thomas Oberlin
\end_layout

\begin_layout Standard
\align center
Dr.
 Bastien Plazolles
\end_layout

\begin_layout Standard
\align block
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vskip 4cm
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align block

\shape smallcaps
Institut National des Sciences Appliquées de Toulouse
\end_layout

\begin_layout Standard
\align block

\shape smallcaps
Département Génie Mathématique et Modélisation
\end_layout

\begin_layout Standard
\align block
\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Abstract
dadas
\end_layout

\begin_layout Part*
\begin_inset Newpage clearpage
\end_inset

Acknowledgment
\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Standard
\align block
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\align block
\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Part
Introduction
\end_layout

\begin_layout Standard
\align block
\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Part
Practicum context
\end_layout

\begin_layout Section
Monitoring of basement structures and water-saturated ground
\end_layout

\begin_layout Section
Seismic inversion problem by arrival time picking
\end_layout

\begin_layout Subsection
Introduction to body waves
\end_layout

\begin_layout Standard
Waves can be defined as a disturbance in materials that carries energy and
 propagates.
 Energy waves generated by an earthquake or an artificial explosion.
 In general, an elastic material through which the wave propagates does
 not move with the wave.
 The movement of the material is considered as small motion as the wave
 passes.
 In other words, after the wave has passed, the material usually is not
 changed at all and looks just like it did before the wave.
 When an earthquake takes place or when an explosion or mechanical device
 is used to initiate a seismic disturbance artificially, a complex field
 of seismic waves is generated.
 Waves that travel through the interior of the Earth are called body waves
 
\begin_inset CommandInset citation
LatexCommand cite
key "SelimSaleh2011"
literal "false"

\end_inset

.
 They follow ray paths bent by varying density and modulus (stiffness) of
 the Earth's interior that are affected by composition, phase and temperature.
 There are two main kinds of body waves that are detected by a seismograph:
\end_layout

\begin_layout Itemize
compression waves (P-waves) that are wave motion in the direction the wave
 is traveling;
\end_layout

\begin_layout Itemize
shear waves (S-waves) that are involving a back-and-forth shearing motion
 at right angles to the direction the wave is traveling.
 
\end_layout

\begin_layout Standard
\noindent
P-waves travel faster and they are the first waves to arrive from the earthquake
, closely followed by its reflection from the surface and S-waves arrive
 next (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig_seismograph"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
 Moreover, the P-wave can travel through liquids and solids while the S-wave
 can only travel through solids (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig_motions-s-p-waves"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figs/seismograph.gif
	scale 55

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Body waves on seismograph
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig_seismograph"

\end_inset


\end_layout

\begin_layout Plain Layout
\align center

\shape italic
Source:
\shape default
 
\begin_inset Flex URL
status collapsed

\begin_layout Plain Layout

http://earthsci.org/education/teacher/basicgeol/earthq/earthq.html
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figs/p-s-waves.gif
	scale 50
	rotateOrigin center

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Motion of P-wave and S-wave
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig_motions-s-p-waves"

\end_inset


\end_layout

\begin_layout Plain Layout
\align center

\shape italic
Source:
\shape default
 
\begin_inset Flex URL
status collapsed

\begin_layout Plain Layout

https://www.mathsisfun.com/physics/waves-seismic.html
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Classical seismic arrival time picking methods
\end_layout

\begin_layout Section
Automatic arrival time picking by deep learning
\end_layout

\begin_layout Standard
\align block
\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Part
PhaseNet: A deep neural network for seismic arrival time picking
\end_layout

\begin_layout Standard
PhaseNet is a deep-neural-network-based arrival-time picking method that
 uses three-component seismic waveform as input and returns probability
 distributions of arrival times of both P-wave and S-wave and also noise
 as output.

\shape italic
 
\shape default
We note that picking S arrivals is more challenging for automatic method
 because the S-waves are not the first arriving waves and thus, they emerge
 from the scattered waves of the P coda.
 PhaseNet model showed a significant improvement compared to the models
 which do not utilize the deep neural network, particularly, a very higher
 precision of predicted time picking with S-waves in 
\begin_inset CommandInset citation
LatexCommand cite
key "berozaPhaseNet"
literal "false"

\end_inset

.
 This model is related to U-net that is used for biomedical image segmentation
 and particularly, showed its efficiencies for segmentation of neuronal
 structures in electron microscopic stacks in 
\begin_inset CommandInset citation
LatexCommand cite
key "UnetDL"
literal "false"

\end_inset

.
 Both models have a quite close architecture with symmetrical form, skip
 connections, etc..
 We will see in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Transpose-convolutional-layers:"
plural "false"
caps "false"
noprefix "false"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Skip-connections"
plural "false"
caps "false"
noprefix "false"

\end_inset

 two essential techniques that are used in the architectures of U-net and
 PhaseNet.
\end_layout

\begin_layout Section
Explanation of the network structure
\end_layout

\begin_layout Subsection
Transpose convolutional layers: Deconvolution 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Transpose-convolutional-layers:"

\end_inset


\end_layout

\begin_layout Standard
Transposed convolution, or deconvolution, or upsampling is now appearing
 in many of CNN architectures.
 This technique exists in symmetrical architectures (encoder-decoder) and
 can be used to reconstruct the original representation of a convolution
 filter map by using transposed convolution.
 Firstly, the kernels in this architecture can be learnt over time thanks
 to regular convolutional layers (compressing input data) and then can be
 used to define the transposed convolution in order to find the original
 data (decompression) 
\begin_inset CommandInset citation
LatexCommand cite
key "deconvolution_Chris"
literal "false"

\end_inset

.
 But how does this work exactly? Let's take a look at what does a normal
 convolution do.
\end_layout

\begin_layout Standard
Considering a simple example that we want to apply a convolution with a
 2x2 kernel on a 3x3 input image as below:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Formula $input:\begin{bmatrix}2 & 1 & 4\\
1 & 3 & 1\\
5 & 4 & 2
\end{bmatrix}$
\end_inset

 *convolution operation* 
\begin_inset Formula $kernel:\begin{bmatrix}2 & 1\\
1 & 2
\end{bmatrix}$
\end_inset

.
\end_layout

\begin_layout Standard
\noindent
We assume a stride of 1, so the convolution process is that the kernel is
 first placed at the upper left corner of the input matrix.
 Subsequently, it performs a Hadamard product (element-wise multiplication)
 with the overlapping area of the input.
 We repeat this operation for the next position of the kernel (for example,
 one step shift to the right) and so on.
 Thus, we obtain the convolution below:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Formula $\begin{bmatrix}2 & 1 & 4\\
1 & 3 & 1\\
5 & 4 & 2
\end{bmatrix}*\begin{bmatrix}2 & 1\\
1 & 2
\end{bmatrix}=\begin{bmatrix}12 & 11\\
18 & 15
\end{bmatrix}$
\end_inset

.
\end_layout

\begin_layout Standard
\noindent
Now, if we consider a flatten input matrix of the size 9x1 instead of 3x3,
 and a convolution matrix that demonstrates all positions of the kernel
 on the input (i.e.
 each row of this convolution matrix represents a position of the kernel
 on top of the input).
 Hence, the convolution operation is just like the matrix multiplication
 between the convolution matrix and the flatten input matrix:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Formula $\begin{bmatrix}2 & 1 & 0 & 1 & 2 & 0 & 0 & 0 & 0\\
0 & 2 & 1 & 0 & 1 & 2 & 0 & 0 & 0\\
0 & 0 & 0 & 2 & 1 & 0 & 1 & 2 & 0\\
0 & 0 & 0 & 0 & 2 & 1 & 0 & 1 & 2
\end{bmatrix}.\begin{bmatrix}2\\
1\\
4\\
1\\
3\\
1\\
5\\
4\\
2
\end{bmatrix}=\begin{bmatrix}12\\
11\\
18\\
15
\end{bmatrix}\text{⟶}\begin{bmatrix}12 & 11\\
18 & 15
\end{bmatrix}$
\end_inset

.
\end_layout

\begin_layout Standard
So, if we try to go backward from a summarized version of the original input
 to the original input, or at least something that hopefully looks like
 it, we just need to try to multiply the transposed convolution matrix with
 the flatten compressed input matrix.
 For instance, we want to perform an upsampling for a compressed matrix
 
\begin_inset Formula $\begin{bmatrix}1 & 2\\
3 & 5
\end{bmatrix}$
\end_inset

with the same kernel in the previous example, so the decompression process
 is simply described as below: 
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Formula $\begin{bmatrix}2 & 0 & 0 & 0\\
1 & 2 & 0 & 0\\
0 & 1 & 0 & 0\\
1 & 0 & 2 & 0\\
2 & 1 & 1 & 2\\
0 & 2 & 0 & 1\\
0 & 0 & 1 & 0\\
0 & 0 & 2 & 1\\
0 & 0 & 0 & 2
\end{bmatrix}.\begin{bmatrix}1\\
2\\
3\\
5
\end{bmatrix}=\begin{bmatrix}2\\
5\\
2\\
7\\
17\\
9\\
3\\
11\\
10
\end{bmatrix}⟶\begin{bmatrix}2 & 5 & 2\\
7 & 17 & 9\\
3 & 11 & 10
\end{bmatrix}$
\end_inset

.
\end_layout

\begin_layout Subsection
Skip connections 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Skip-connections"

\end_inset


\end_layout

\begin_layout Standard
Currently, skip connection is a standard module in many Convolutional Neural
 Network (CNN) architectures.
 It plays a very important role in the fact of building a 
\begin_inset Quotes eld
\end_inset

fully convolutional network
\begin_inset Quotes erd
\end_inset

 (FCN) 
\begin_inset CommandInset citation
LatexCommand cite
key "Long_2015_CVPR"
literal "false"

\end_inset

.
 Comparing with CNN, standard FCNs are either added an expanding path (decoder)
 that recovers spatial information (updated parameters: weights, biases)
 by merging features skipped from the various resolution levels on the contracti
ng path (encoder), we call 
\begin_inset Quotes eld
\end_inset

long skip connections
\begin_inset Quotes erd
\end_inset

 (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "skip connections-steup"
plural "false"
caps "false"
noprefix "false"

\end_inset

a), or extended by adding 
\begin_inset Quotes eld
\end_inset

short skip connection
\begin_inset Quotes erd
\end_inset

 (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "skip connections-steup"
plural "false"
caps "false"
noprefix "false"

\end_inset

b) in order to increase the convergence speed of the loss function and build
 very deep neural networks that can contain hundreds of layers 
\begin_inset CommandInset citation
LatexCommand cite
key "skipconnectImportance"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename figs/setup_skipconection.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Two kinds of setup of skip connection
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "skip connections-steup"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
To understand how does the skip connection work, we first go back to understand
 a little bit of the principal of 
\begin_inset Quotes eld
\end_inset

backpropagation algorithm
\begin_inset Quotes erd
\end_inset

.
 As we know, neural networks can learn their weights and biases using the
 gradient descent algorithm in order to optimize these parameters with respect
 to the loss function.
 The backpropagation algorithm provides us with a way to calculating the
 gradient of the loss function by computing the partial derivatives.
 However, in some cases, we can see that the loss function stop decreasing
 but it is still far way from the desired result at a certain step of updating
 parameters during the training step.
 The so-called 
\begin_inset Quotes eld
\end_inset

vanishing gradient problem
\begin_inset Quotes erd
\end_inset

 causes an uninterrupted gradient flow from the first layer to the last
 layer in our model 
\begin_inset CommandInset citation
LatexCommand cite
key "skipconnection"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
Mathematically, if 
\begin_inset Formula $W$
\end_inset

 is a parameter that we want to learn for during the training, then the
 updating step is:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Formula $W_{new}=W_{old}-\lambda\frac{\partial L}{\partial W}$
\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $\lambda$
\end_inset

 is the learning rate and 
\begin_inset Formula $L$
\end_inset

 is the loss function.
 Now we assume a simple neural network with training data set 
\begin_inset Formula $(X,Y)$
\end_inset

, kernel 
\begin_inset Formula $f$
\end_inset

, weights 
\begin_inset Formula $W$
\end_inset

, biases 
\begin_inset Formula $b$
\end_inset

, associated activation function 
\begin_inset Formula $\phi$
\end_inset

 and loss function 
\begin_inset Formula $L$
\end_inset

 as Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "simpleCNN"
plural "false"
caps "false"
noprefix "false"

\end_inset

:
\end_layout

\begin_layout Standard
\noindent
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename figs/cnn simple.png
	scale 75

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Simple architecture of CNN
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "simpleCNN"

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
Then, for calculating the quantity 
\begin_inset Formula $\frac{\partial L}{\partial W}$
\end_inset

, we need to go backward to calculate the partial derivatives:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Formula $\frac{\partial L}{\partial W}=\frac{\partial L}{\partial y}.\frac{\partial y}{\partial z_{2}}.\frac{\partial z_{2}}{\partial W}$
\end_inset

.
\end_layout

\begin_layout Standard
\noindent
In some cases, if we have a large number of layers when we go backward through
 the network, then the gradient of the network becomes smaller and will
 close to 0.
 This causes the problem of vanishing gradient.
\end_layout

\begin_layout Standard
Thus, skip connections allow to avoid the vanishing gradient problem.
 They provide an alternative path for the gradient (with backpropagation)
 by skipping some layer in the deep architecture and feeding the output
 of one layer as the input to the next layers (instead of only the next
 one).
 Beside, there is another reason to use skip connections that we want to
 capture some information in the initial layers which allow the later layers
 to also learn from them.
 In general, there are two main kinds of skip connections we usually use
 in Deep Learning: ResNet 
\begin_inset CommandInset citation
LatexCommand cite
key "ResNet_He_2016_CVPR"
literal "false"

\end_inset

 or addictive skip connection backpropagates through the identity function
 by using a vector addition (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "skip connections"
plural "false"
caps "false"
noprefix "false"

\end_inset

a) while DenseNet 
\begin_inset CommandInset citation
LatexCommand cite
key "DenseNet_Huang_2017_CVPR"
literal "false"

\end_inset

 or concatenative skip connection allows to avoid the fact of having low-level
 information shared between the input and output, by concatenation of previous
 feature maps (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "skip connections"
plural "false"
caps "false"
noprefix "false"

\end_inset

b).
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename figs/Additive-skip-connections-vs-concatenative-skip-connections-Rectangles-represent-data.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Additive connection and concatenative skip connection
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "skip connections"

\end_inset


\end_layout

\begin_layout Plain Layout
\align center

\shape italic
Source:
\shape default
 
\begin_inset Flex URL
status collapsed

\begin_layout Plain Layout

https://www.researchgate.net/figure/Additive-skip-connections-vs-concatenative-ski
p-connections-Rectangles-represent-data_fig1_329115979
\end_layout

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Go back to the long skip connections that are used in symmetrical architecture
 (convolution-deconvolution or encoder-decoder) as U-net or PhaseNet.
 These skip connections allow to recover fine-grained details and the full
 spatial resolution at the expanding path in order to improve significantly
 prediction results.
 Effectively, the experiments in 
\begin_inset CommandInset citation
LatexCommand cite
key "nikolas_DLMIS"
literal "false"

\end_inset

 show that adding long skip connections in the encoder-decoder architecture
 can achieve a incredibly effective work in medical image segmentation.
\end_layout

\begin_layout Subsection
Architectural model
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "phasenet_architec"
plural "false"
caps "false"
noprefix "false"

\end_inset

 shows the architecture of PhaseNet with two symmetrical branches containing
 4 downsampling stages and 4 upsampling stages.
 Each stage is a convolution followed by ReLU activation function.
 The downsampling stages compress the input signal and reduce the size of
 the data.
 Afterwards, the up-sampling stages expand and convert the useful information
 into probability distributions of the outputs for each time point.
 The skip connection used in each up-sampling stage allows to concatenate
 directly the left output to the right layer without going through the deep
 layers between them.
 
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename figs/phasenet_architec.png
	scale 35

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
PhaseNet architecture
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "phasenet_architec"

\end_inset


\end_layout

\begin_layout Plain Layout
\align center

\shape italic
Taken from 
\begin_inset CommandInset citation
LatexCommand cite
key "berozaPhaseNet"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The input are three-component seismograms with the labels is the corresponding
 arrival times
\begin_inset Foot
status open

\begin_layout Plain Layout
PhaseNet takes the arrival times as labels but what the network really takes
 is the probability distributions of the arrival times (see in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Arrival-times-and-pick-proba-conversion"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
\end_layout

\end_inset

, and the output are probability distributions of P-waves, S-waves and noise.
 Let 
\begin_inset Formula $x$
\end_inset

 be a time series of the input, 
\begin_inset Formula $z(x)$
\end_inset

 be the unscaled values of the last layer and 
\begin_inset Formula $j=1,2,3$
\end_inset

 represent noise, P-wave and S-wave respectively.
 So we utilize the soft-max normalized exponential function to calculate
 the probability of each category (noise, P-wave, S-wave) at each time point:
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $q_{j}(x)=\frac{e^{z_{j}(x)}}{\sum_{i=1}^{3}e^{z_{i}(x)}}$
\end_inset

.
\end_layout

\begin_layout Standard
\noindent
Finally, we define the loss function by using cross entropy between the
 true probability distribution 
\begin_inset Formula $p(x)$
\end_inset

 and predicted distribution 
\begin_inset Formula $q(x)$
\end_inset

:
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $H(p,q)=-\sum_{i=1}^{3}\sum_{x}p_{i}(x)\log q_{i}(x)$
\end_inset

.
\end_layout

\begin_layout Section
?????
\end_layout

\begin_layout Subsection
Data extraction
\begin_inset CommandInset label
LatexCommand label
name "sec:Data-extraction"

\end_inset


\end_layout

\begin_layout Standard
For training on a data set, PhaseNet takes the seismograms having shape
 of 9000 while the network takes an input size 3001.
 It comes to the fact that we want the network to learn the essential informatio
n of our data and also learn to detect noises.
 Concretely, for each seismogram, the data prepossessing step will randomly
 extract 3001 points which is around the labels (the true arrival times)
 with a chance of 0.95 (this threshold can be calibrated of course).
 In this case, each seismogram of size 3001 is labeled with a list of arrival
 times of P and S-wave.
 On the contrary, with a chance of 0.05, we randomly extract a part of size
 3001 which only contains the noises (a part in which the arrival times
 are not observed) and then these seismograms are labeled with empty lists.
\end_layout

\begin_layout Subsection
Arrival times and probability distributions conversion
\begin_inset CommandInset label
LatexCommand label
name "sec:Arrival-times-and-pick-proba-conversion"

\end_inset


\end_layout

\begin_layout Standard
As we know, PhaseNet takes the arrival times of P and S-wave as the label
 input for the training and returns the time picking of these both waves
 as the output for the prediction, while the network takes and returns the
 probability distributions of the arrival times (because the loss function
 is based on cross entropy between the true probability distribution and
 predicted distribution).
 So we want to find out how PhaseNet converts from the point times to the
 probability distributions before the input of the network (in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Generating-picks-probability"
plural "false"
caps "false"
noprefix "false"

\end_inset

) and from the probability distributions to the time picking after the output
 of the network (in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Detecting-arrival-times"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
\end_layout

\begin_layout Subsubsection
Generating probability distributions from arrival times
\begin_inset CommandInset label
LatexCommand label
name "subsec:Generating-picks-probability"

\end_inset


\end_layout

\begin_layout Standard
Seeing that the network takes the probability distribution of P, S-waves
 and noise as labels, so we need to generate them from the arrival times.
 As we saw previously in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Data-extraction"
plural "false"
caps "false"
noprefix "false"

\end_inset

, the extracted data is either the noise part (with a chance of 5%), or
 the essential part (with a chance of 95%).
 In the first case, we realize a label as the zero probability distributions
 for P and S-wave, and the one probability distribution for the noise (Figure
 
\begin_inset CommandInset ref
LatexCommand ref
reference "noise=1"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename /home/nnthuynh/Desktop/stage_5A/realisation/compte-rendu/figs/input_label_noise=1.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Output probability distributions when the extracted data is the noise part
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "noise=1"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
In the second case, we realize the label as the symmetrical distribution.
 The mean of this distribution is the arrival time of P-wave (or S-wave)
 and we compute the probability for a calibratable number of points around
 the mean (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "noise/=1"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
 
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename /home/nnthuynh/Desktop/stage_5A/realisation/compte-rendu/figs/P-S-noise.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Output probability distributions realized with 50 points around the mean
 when the extracted data is the essential part
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "noise/=1"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Detecting arrival times from probability distributions 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Detecting-arrival-times"

\end_inset


\end_layout

\begin_layout Standard
Now, we want to pick up the arrival times from the probability distributions
 returned by the network.
 The 
\family sans
detect_peaks()
\family default
 function allows to detect the peaks in the data (the output of the network)
 based on their amplitude and other features.
 By default, the function will detect all peaks in the data (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "all_peaks"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename /home/nnthuynh/Desktop/stage_5A/realisation/compte-rendu/figs/all_peaks.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Detecting all peaks in the data
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "all_peaks"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Beside, there are some calibratable parameters based on criterion as:
\end_layout

\begin_layout Itemize
detect peaks that are greater than minimum peak height (mph).
 For instance, if we set a value of 6 for the parameter based on this criteria
 for a data as Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "mph"
plural "false"
caps "false"
noprefix "false"

\end_inset

, so the function only detect the peak which are not less than 6 (peak at
 index 8) but do not detect the three peaks at index 1, 3 and 11 which are
 less than 6.
\end_layout

\begin_layout Itemize
detect peaks that are at least separated by minimum peak distance in number
 of data (mpd).
 For instance, if we consider Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "mpd"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we can see that the biggest peak is 7 (at index 8) and this peak is picked
 up at first.
 If we set the value of the peak distance is 3, so the peak at index 11
 is not picked up as the distance from it to the peak at index 8 is 3 (there
 are 2 points between them) that is not greater than 3.
 On the contrary, the peak at index 3 is picked up and the peak at index
 1 is not by the same way.
\end_layout

\begin_layout Itemize
detect peaks that are greater than a threshold in relation to their immediate
 neighbors.
 In Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "threshold"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we chose the value of threshold is 2, so the peak at index 3 is not picked
 up because the gap between its amplitude and the amplitude of its neighbor
 (here is the neighbor at index 4) is 1 (
\begin_inset Formula $=2-1$
\end_inset

) that is less than 2.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename /home/nnthuynh/Desktop/stage_5A/realisation/compte-rendu/figs/mph.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Detecting peaks in the data with the mph criteria
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "mph"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename /home/nnthuynh/Desktop/stage_5A/realisation/compte-rendu/figs/mpd.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Detecting all peaks in the data with the mpd criteria
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "mpd"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename /home/nnthuynh/Desktop/stage_5A/realisation/compte-rendu/figs/threshold.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Detecting all peaks in the data with the threshold criteria
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "threshold"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Testing and scoring metrics
\end_layout

\begin_layout Standard
For evaluating the fitting of model with the data set, the method chosen
 is the evaluation metrics: precision, recall and F1 score that measure
 the performance of the model on the test data set.
 We assume that peaks probabilities above 0.5 are called as positive picks.
 Moreover, those which have large arrival-time residuals (greater than 0.1s)
 are counted as false positives (false predictive values) and which have
 small residuals are counted as true positives (true predictive values).
 Arrival-times which are relevant elements but are not among the predicted
 values are called false negatives.
 Precision is so the fraction between the number of true positives and the
 total number of predicted values:
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $P=\frac{T_{p}}{T_{p}+F_{p}}$
\end_inset

.
\end_layout

\begin_layout Standard
\noindent
Namely, precision describes the precision of predictive values.
 On the other hand, recall refers to the percentage of total relevant results
 correctly classified:
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $R=\frac{T_{p}}{T_{p}+F_{n}}$
\end_inset

.
\end_layout

\begin_layout Standard
For instance, if we work for a test data that contains 154 samples (154
 seismograms).
 Among these 154 samples, we find that the P-waves for example appear 142
 times in reality (so the number of relevant elements is 142).
 Then, the model predicts that the P-waves appear 144 times (i.e.
 there are 144 peak probabilities of P-waves that overtake 0.5), so the positive
 picks (the total number of predictive values) is 144.
 Now, we find that among these 144 positive picks, there are 134 predicted
 values whose residual is less than 0.1s, so the number of true positives
 is 134 while that of false positives is 
\begin_inset Formula $144-134=10$
\end_inset

.
 Thus, the number of false negatives is 
\begin_inset Formula $142-134=8$
\end_inset

.
 Hence, precision and recall are respectively:
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $P=\frac{134}{144},R=\frac{134}{142}$
\end_inset

.
\end_layout

\begin_layout Standard
In some cases, we can get a very high precision but a very low recall.
 For example, if we set a very high threshold for positive picks, only the
 best picks are reported positive which is only a small portion of total
 true picks.
 So F1 score gives us a balanced criterion between precision and recall:
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $F1=2\frac{PR}{P+R}$
\end_inset

.
\end_layout

\begin_layout Standard
Actually, F1 scores evaluating the performance of PhaseNet model on their
 own test data (with 154 samples) achieved 0.937 for P-waves and 0.853 for
 S-waves, that shows a glorious improvement comparing with results obtained
 by classical methods.
 
\end_layout

\begin_layout Section
Code execution
\end_layout

\begin_layout Standard
The PhaseNet model is trained on the available data set that contains more
 than 0.7 million seismograms from natural earthquake and stored in directory
 
\family sans
/model
\family default
 (weights and importance information of model were saved after finishing
 the training).
 If we want the model to be adapted to a new data set, we have to retrain
 it, either from scratch, or from a pre-trained model (see 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Training-on-new-phasenet"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
 Now, assuming that we want to use this pre-trained model to predict the
 arrival time of the waves and noise for the signals stored in directory
 
\family sans
waveform_pred
\family default
.
 This directory consists of many samples.
 Each sample consists of three seismograms corresponding to three-component
 signals (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "input_signals"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename figs/three-component.png
	scale 55

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Three-component signals of a sample
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "input_signals"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
Concretely, we tape the command below:
\end_layout

\begin_layout Verbatim

$ python run.py --mode=pred --model_dir=model/model_name --data_dir=waveform_pred
\end_layout

\begin_layout Standard
\noindent
where 
\family sans
model_name
\family default
 is the pre-trained model.
 The outputs are the probability distributions of noise, P-wave and S-wave
 (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "proba_output"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
 
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename figs/ouput.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Probability distributions of noise, P-wave and S-wave obtained by prediction
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "proba_output"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
We can further interpret that, at time 
\begin_inset Formula $t$
\end_inset

, the probability that we can observe noise is equal to one minus the probabilit
y that we can observe the P-wave and minus the probability that we can observe
 the S-wave (as we have used the soft-max normalized exponential function
 in the last layer):
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Formula $\mathbb{P}(noise=t)=1-\mathbb{P}(\text{P-wave}=t)-\mathbb{P}(\text{S-wave}=t)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "phasenet_and_transfer"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "fangshu2019"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "references"
options "siam"

\end_inset


\end_layout

\end_body
\end_document
